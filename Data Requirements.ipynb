{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step No. 1: Data Extraction\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Step No. 1: Data Extraction\n",
    "try:\n",
    "    # Load the data from the local CSV file\n",
    "    file_path = r'C:\\Users\\N I T R O   5\\Documents\\Bootcamps\\Purwadhika\\Capstone\\data_sources\\data_sources\\data_reqruitment\\data_requirements.csv'\n",
    "    data = pd.read_csv(file_path)\n",
    "    print(\"Step No. 1: Data Extraction\")\n",
    "    print(\"-\" * 80)\n",
    "except Exception as e:\n",
    "    print(f\"Step No. 1: Data Extraction Failed. Error: {e}\")\n",
    "    print(\"-\" * 80)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\N I T R O   5\\AppData\\Local\\Temp\\ipykernel_30564\\381404926.py:24: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  data_cleaned.loc[:, 'salary_estimate'] = data_cleaned['salary_estimate'].apply(standardize_salary)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step No. 2: Data Transformation\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Step No. 2: Data Transformation\n",
    "try:\n",
    "    # Remove unnecessary index column if exists\n",
    "    if 'Unnamed: 0' in data.columns:\n",
    "        data.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "        \n",
    "    # Remove the job description column\n",
    "    if 'job_description' in data.columns:\n",
    "        data.drop(columns=['job_description'], inplace=True)\n",
    "\n",
    "    # Remove rows with any empty cells\n",
    "    data_cleaned = data.dropna().copy()\n",
    "\n",
    "    # Standardize salary_estimate column (keeping as-is)\n",
    "    def standardize_salary(salary):\n",
    "        try:\n",
    "            # Remove (est.) and extract the numeric part\n",
    "            salary_value = re.sub(r'[\\(\\)est.]', '', salary).strip()\n",
    "            salary_value = re.findall(r'[\\d,]+', salary_value)[0]\n",
    "            return float(salary_value.replace(',', ''))\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    data_cleaned.loc[:, 'salary_estimate'] = data_cleaned['salary_estimate'].apply(standardize_salary)\n",
    "\n",
    "    # Skip salary_numeric transformation as requested\n",
    "\n",
    "    # Clean up company_type column to remove 'Company - ' prefix\n",
    "    # Retain only the company type without the 'Company - ' prefix\n",
    "    data_cleaned.loc[:, 'company_type'] = data_cleaned['company_type'].str.replace(r'^Company - ', '', regex=True)\n",
    "\n",
    "    # Remove rows where company_size contains a date-like string\n",
    "    date_pattern = r'\\d{4}'\n",
    "    data_cleaned = data_cleaned[~data_cleaned['company_size'].str.contains(date_pattern, na=False)]\n",
    "\n",
    "    # Shorten company_size column\n",
    "    def shorten_company_size(size):\n",
    "        try:\n",
    "            return size.replace('Employees', '').replace('to', '-').strip()\n",
    "        except:\n",
    "            return size\n",
    "\n",
    "    data_cleaned.loc[:, 'company_size'] = data_cleaned['company_size'].apply(shorten_company_size)\n",
    "\n",
    "    # Convert date column to 'Asia/Jakarta' timezone\n",
    "    def convert_to_jakarta_timezone(date_str):\n",
    "        try:\n",
    "            date_obj = datetime.fromisoformat(date_str)\n",
    "            jakarta_timezone = pytz.timezone('Asia/Jakarta')\n",
    "            date_obj_jakarta = date_obj.astimezone(jakarta_timezone)\n",
    "            return date_obj_jakarta\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "    # Apply date transformation\n",
    "    data_cleaned.loc[:, 'dates_jakarta'] = data_cleaned['dates'].apply(convert_to_jakarta_timezone)\n",
    "\n",
    "    print(\"Step No. 2: Data Transformation\")\n",
    "    print(\"-\" * 80)\n",
    "except Exception as e:\n",
    "    print(f\"Step No. 2: Data Transformation Failed. Error: {e}\")\n",
    "    print(\"-\" * 80)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step No. 3: Top 3 Companies with Highest Rating\n",
      "                             company  company_rating\n",
      "834         APPIC Solutions LLC\\n5.0             5.0\n",
      "495         Slide Insurance LLC\\n5.0             5.0\n",
      "322  Stonehenge Technology Labs\\n5.0             5.0\n",
      "--------------------------------------------------------------------------------\n",
      "Step No. 4: Top 5 Locations with Most Jobs\n",
      "Remote            41\n",
      "New York, NY      14\n",
      "Atlanta, GA       12\n",
      "Washington, DC     9\n",
      "Austin, TX         9\n",
      "Name: location, dtype: int64\n",
      "--------------------------------------------------------------------------------\n",
      "Step No. 5: Job Title Counts\n",
      "Data Engineer                            90\n",
      "Senior Data Engineer                     34\n",
      "Sr. Data Engineer                         9\n",
      "AWS Data Engineer                         6\n",
      "Azure Data Engineer                       6\n",
      "                                         ..\n",
      "Data Engineer - Remote US                 1\n",
      "GEM Data Engineer                         1\n",
      "Data Quality Engineer                     1\n",
      "Lead Azure Data Engineer                  1\n",
      "Data Engineer - TS/SCI with Polygraph     1\n",
      "Name: job_title, Length: 125, dtype: int64\n",
      "--------------------------------------------------------------------------------\n",
      "Step No. 6: salary_numeric column is missing.\n",
      "--------------------------------------------------------------------------------\n",
      "Step No. 7: Top 3 Company Sizes\n",
      "51 - 200     140\n",
      "201 - 500     95\n",
      "1 - 50        51\n",
      "Name: company_size, dtype: int64\n",
      "--------------------------------------------------------------------------------\n",
      "Step No. 8: Company Size Count\n",
      "51 - 200     140\n",
      "201 - 500     95\n",
      "1 - 50        51\n",
      "Unknown        4\n",
      "Name: company_size, dtype: int64\n",
      "--------------------------------------------------------------------------------\n",
      "Step No. 9: Company Type Count\n",
      "Private                           257\n",
      "Nonprofit Organization             11\n",
      "Public                              8\n",
      "Subsidiary or Business Segment      6\n",
      "Unknown                             3\n",
      "Government                          3\n",
      "Contract                            1\n",
      "Private Practice / Firm             1\n",
      "Name: company_type, dtype: int64\n",
      "--------------------------------------------------------------------------------\n",
      "Step No. 10: Company Sector Count\n",
      "Information Technology                         157\n",
      "Management & Consulting                         31\n",
      "Human Resources & Staffing                      14\n",
      "Healthcare                                      12\n",
      "Financial Services                              12\n",
      "Media & Communication                            9\n",
      "Education                                        8\n",
      "Government & Public Administration               6\n",
      "Retail & Wholesale                               6\n",
      "Arts, Entertainment & Recreation                 6\n",
      "Insurance                                        6\n",
      "Manufacturing                                    4\n",
      "Pharmaceutical & Biotechnology                   3\n",
      "Personal Consumer Services                       2\n",
      "Energy, Mining & Utilities                       2\n",
      "Hotels & Travel Accommodation                    2\n",
      "Nonprofit & NGO                                  2\n",
      "Transportation & Logistics                       2\n",
      "Aerospace & Defense                              2\n",
      "Agriculture                                      1\n",
      "Telecommunications                               1\n",
      "Legal                                            1\n",
      "Construction, Repair & Maintenance Services      1\n",
      "Name: company_sector, dtype: int64\n",
      "--------------------------------------------------------------------------------\n",
      "Step No. 11: Company with the Biggest Revenue\n",
      "company            AGM Tech Solutions\\n4.8\n",
      "company_revenue    $5 to $25 million (USD)\n",
      "Name: 8, dtype: object\n",
      "--------------------------------------------------------------------------------\n",
      "Step No. 12: Revenue Classification Count\n",
      "Unknown         134\n",
      "1-1 billion      89\n",
      "10+ billion      65\n",
      "5-10 billion      2\n",
      "Name: revenue_classification, dtype: int64\n",
      "--------------------------------------------------------------------------------\n",
      "Step No. 13: salary_numeric column is missing.\n",
      "--------------------------------------------------------------------------------\n",
      "Step No. 14: salary_numeric column is missing, unable to perform salary statistics.\n",
      "--------------------------------------------------------------------------------\n",
      "Step No. 3: Data Demography Analysis\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Step No. 3: Data Demography Analysis\n",
    "try:\n",
    "    # Top 3 companies with the highest rating\n",
    "    top_3_companies = data_cleaned.sort_values(by='company_rating', ascending=False).head(3)[['company', 'company_rating']]\n",
    "    print(\"Step No. 3: Top 3 Companies with Highest Rating\")\n",
    "    print(top_3_companies)\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    # Top 5 Locations with the Most Jobs\n",
    "    top_5_locations = data_cleaned['location'].value_counts().head(5)\n",
    "    print(\"Step No. 4: Top 5 Locations with Most Jobs\")\n",
    "    print(top_5_locations)\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    # Sum of each job title\n",
    "    job_title_counts = data_cleaned['job_title'].value_counts()\n",
    "    print(\"Step No. 5: Job Title Counts\")\n",
    "    print(job_title_counts)\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    # Job with the highest salary estimation\n",
    "    if 'salary_numeric' in data_cleaned.columns:\n",
    "        top_salary_job = data_cleaned.loc[data_cleaned['salary_numeric'].idxmax()][['job_title', 'salary_numeric']]\n",
    "        print(\"Step No. 6: Job with the Highest Salary Estimation\")\n",
    "        print(top_salary_job)\n",
    "    else:\n",
    "        print(\"Step No. 6: salary_numeric column is missing.\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    # Top 3 company sizes\n",
    "    top_3_company_sizes = data_cleaned['company_size'].value_counts().head(3)\n",
    "    print(\"Step No. 7: Top 3 Company Sizes\")\n",
    "    print(top_3_company_sizes)\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    # Count of each company size\n",
    "    company_size_count = data_cleaned['company_size'].value_counts()\n",
    "    print(\"Step No. 8: Company Size Count\")\n",
    "    print(company_size_count)\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    # Count of each company type\n",
    "    company_type_count = data_cleaned['company_type'].value_counts()\n",
    "    print(\"Step No. 9: Company Type Count\")\n",
    "    print(company_type_count)\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    # Count of each company sector\n",
    "    company_sector_count = data_cleaned['company_sector'].value_counts()\n",
    "    print(\"Step No. 10: Company Sector Count\")\n",
    "    print(company_sector_count)\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    # Company with the biggest revenue\n",
    "    if 'company_revenue_standard' not in data_cleaned.columns:\n",
    "        data_cleaned['company_revenue_standard'] = data_cleaned['company_revenue'].apply(lambda x: re.sub(r'[^0-9]', '', str(x)))\n",
    "    biggest_revenue_company = data_cleaned.sort_values(by='company_revenue_standard', ascending=False).iloc[0][['company', 'company_revenue']]\n",
    "    print(\"Step No. 11: Company with the Biggest Revenue\")\n",
    "    print(biggest_revenue_company)\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    # Count companies in revenue classification\n",
    "    def classify_revenue(revenue):\n",
    "        if revenue is None or revenue == '':\n",
    "            return 'Unknown'\n",
    "        revenue = int(revenue)\n",
    "        if revenue < 1000:\n",
    "            return '1-1 billion'\n",
    "        elif 1000 <= revenue < 5000:\n",
    "            return '1-5 billion'\n",
    "        elif 5000 <= revenue < 10000:\n",
    "            return '5-10 billion'\n",
    "        else:\n",
    "            return '10+ billion'\n",
    "\n",
    "    data_cleaned['revenue_classification'] = data_cleaned['company_revenue_standard'].apply(classify_revenue)\n",
    "    revenue_classification_count = data_cleaned['revenue_classification'].value_counts()\n",
    "    print(\"Step No. 12: Revenue Classification Count\")\n",
    "    print(revenue_classification_count)\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    # Top companies with the highest salary numeric (formatted in 10,000 format)\n",
    "    if 'salary_numeric' in data_cleaned.columns:\n",
    "        top_salary_companies = data_cleaned.sort_values(by='salary_numeric', ascending=False).head(10)[['company', 'salary_numeric']]\n",
    "        top_salary_companies['salary_numeric'] = top_salary_companies['salary_numeric'].apply(lambda x: f\"{x:,.0f}\")\n",
    "        print(\"Step No. 13: Top Companies with the Highest Salary Numeric\")\n",
    "        print(top_salary_companies)\n",
    "    else:\n",
    "        print(\"Step No. 13: salary_numeric column is missing.\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    # Smallest, biggest, average, and median salary\n",
    "    if 'salary_numeric' in data_cleaned.columns:\n",
    "        salary_min = data_cleaned['salary_numeric'].min()\n",
    "        salary_max = data_cleaned['salary_numeric'].max()\n",
    "        salary_avg = data_cleaned['salary_numeric'].mean()\n",
    "        salary_median = data_cleaned['salary_numeric'].median()\n",
    "\n",
    "        print(f\"Step No. 14: Salary Statistics\\n Smallest: {salary_min:,.0f}, Biggest: {salary_max:,.0f}, Average: {salary_avg:,.0f}, Median: {salary_median:,.0f}\")\n",
    "    else:\n",
    "        print(\"Step No. 14: salary_numeric column is missing, unable to perform salary statistics.\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    print(\"Step No. 3: Data Demography Analysis\")\n",
    "    print(\"-\" * 80)\n",
    "except Exception as e:\n",
    "    print(f\"Step No. 3: Data Demography Analysis Failed. Error: {e}\")\n",
    "    print(\"-\" * 80)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step No. 4: Data successfully saved to C:\\Users\\N I T R O   5\\Documents\\Bootcamps\\Purwadhika\\Capstone\\data_sources\\data_sources\\data_reqruitment\\cleaned_transformed_data_5.csv\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Step No. 4: Data Loading\n",
    "try:\n",
    "    # Save the cleaned and transformed data to a new CSV file\n",
    "    output_directory = os.path.dirname(file_path)\n",
    "    base_filename = \"cleaned_transformed_data\"\n",
    "    output_file_path = os.path.join(output_directory, f\"{base_filename}.csv\")\n",
    "    \n",
    "    # Check if file exists, if yes, add a number to the filename\n",
    "    file_number = 1\n",
    "    while os.path.exists(output_file_path):\n",
    "        output_file_path = os.path.join(output_directory, f\"{base_filename}_{file_number}.csv\")\n",
    "        file_number += 1\n",
    "\n",
    "    data_cleaned.to_csv(output_file_path, index=False)\n",
    "    print(f\"Step No. 4: Data successfully saved to {output_file_path}\")\n",
    "    print(\"-\" * 80)\n",
    "except PermissionError:\n",
    "    print(f\"Step No. 4: Permission Denied. Please check file permissions or if the file is open in another program.\")\n",
    "    print(\"-\" * 80)\n",
    "except Exception as e:\n",
    "    print(f\"Step No. 4: Data Saving Failed. Error: {e}\")\n",
    "    print(\"-\" * 80)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
